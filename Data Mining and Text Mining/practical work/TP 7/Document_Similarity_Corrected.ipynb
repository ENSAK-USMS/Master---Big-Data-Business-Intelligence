{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7e1f84c",
   "metadata": {},
   "source": [
    "# Document Similarity Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ee04ef",
   "metadata": {},
   "source": [
    "\n",
    "        This notebook aims to create three documents with specific requirements, preprocess them, and then compare their similarities using a custom formula.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6777871b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1: The quick brown fox jumps over the lazy dog. This sentence contains every letter of the alphabet. The fox is quick and brown. \n",
      "He repeatedly does so throughout the day, every day. Observing this, the lazy dog decides it needs to start jumping too. \n",
      "However, the dog is not just lazy but also not as agile as the fox. So, it starts with small leaps. This goes on for weeks, \n",
      "and the dog gradually increases its efforts, inspired by the energetic fox. Despite many falls, the dog keeps trying, aiming \n",
      "to match the fox's agility and speed one day.\n",
      "Document 2: The quick brown fox jumps over the lazy cat. This sentence contains all letters of the alphabet. The fox is fast and brown. \n",
      "Unlike the dog, the cat is intrigued but unmotivated to join. The fox, on the other hand, continues his routines without \n",
      "distraction. Over time, the cat observes and starts to ponder if it could do the same. It's a slow start, but the cat is \n",
      "curious and eventually tries to mimic the fox. The attempts are clumsy at first, but with persistence, the cat improves, \n",
      "becoming a little more like the fox every day.\n",
      "Document 3: Data science involves crunching large datasets to find patterns that are not immediately obvious. It uses statistical methods \n",
      "to analyze data and generate useful business insights. This field combines expertise from several areas such as statistics, \n",
      "machine learning, and software engineering. Data scientists work on various challenges, including prediction models, \n",
      "algorithm design, and data visualization to make data understandable to stakeholders. They also ensure that data \n",
      "privacy and security are maintained, given the sensitive nature of the information handled.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Document Texts with approximately 100 words each\n",
    "doc1 = '''The quick brown fox jumps over the lazy dog. This sentence contains every letter of the alphabet. The fox is quick and brown. \n",
    "He repeatedly does so throughout the day, every day. Observing this, the lazy dog decides it needs to start jumping too. \n",
    "However, the dog is not just lazy but also not as agile as the fox. So, it starts with small leaps. This goes on for weeks, \n",
    "and the dog gradually increases its efforts, inspired by the energetic fox. Despite many falls, the dog keeps trying, aiming \n",
    "to match the fox's agility and speed one day.'''\n",
    "doc2 = '''The quick brown fox jumps over the lazy cat. This sentence contains all letters of the alphabet. The fox is fast and brown. \n",
    "Unlike the dog, the cat is intrigued but unmotivated to join. The fox, on the other hand, continues his routines without \n",
    "distraction. Over time, the cat observes and starts to ponder if it could do the same. It's a slow start, but the cat is \n",
    "curious and eventually tries to mimic the fox. The attempts are clumsy at first, but with persistence, the cat improves, \n",
    "becoming a little more like the fox every day.'''\n",
    "doc3 = '''Data science involves crunching large datasets to find patterns that are not immediately obvious. It uses statistical methods \n",
    "to analyze data and generate useful business insights. This field combines expertise from several areas such as statistics, \n",
    "machine learning, and software engineering. Data scientists work on various challenges, including prediction models, \n",
    "algorithm design, and data visualization to make data understandable to stakeholders. They also ensure that data \n",
    "privacy and security are maintained, given the sensitive nature of the information handled.'''\n",
    "\n",
    "# Display the documents\n",
    "print(\"Document 1:\", doc1)\n",
    "print(\"Document 2:\", doc2)\n",
    "print(\"Document 3:\", doc3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9df502b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1: The quick brown fox jumps over the lazy dog. This sentence contains every letter of the alphabet. The fox is quick and brown.\n",
      "Document 2: The quick brown fox jumps over the lazy cat. This sentence contains all letters of the alphabet. The fox is fast and brown.\n",
      "Document 3: Data science involves crunching large datasets. It uses statistical methods to analyze data and generate useful business insights.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Document Texts\n",
    "doc1 = \"The quick brown fox jumps over the lazy dog. This sentence contains every letter of the alphabet. The fox is quick and brown.\"\n",
    "doc2 = \"The quick brown fox jumps over the lazy cat. This sentence contains all letters of the alphabet. The fox is fast and brown.\"\n",
    "doc3 = \"Data science involves crunching large datasets. It uses statistical methods to analyze data and generate useful business insights.\"\n",
    "\n",
    "# Display the documents\n",
    "print(\"Document 1:\", doc1)\n",
    "print(\"Document 2:\", doc2)\n",
    "print(\"Document 3:\", doc3)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9c5845",
   "metadata": {},
   "source": [
    "## Step 2: Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ccc226f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Document 1: ['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', 'this', 'sentence', 'contains', 'every', 'letter', 'of', 'the', 'alphabet', 'the', 'fox', 'is', 'quick', 'and', 'brown']\n",
      "Preprocessed Document 2: ['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'cat', 'this', 'sentence', 'contains', 'all', 'letters', 'of', 'the', 'alphabet', 'the', 'fox', 'is', 'fast', 'and', 'brown']\n",
      "Preprocessed Document 3: ['data', 'science', 'involves', 'crunching', 'large', 'datasets', 'it', 'uses', 'statistical', 'methods', 'to', 'analyze', 'data', 'and', 'generate', 'useful', 'business', 'insights']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to preprocess text: convert to lowercase, remove punctuation, split into words\n",
    "import string\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()  # convert to lowercase\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # remove punctuation\n",
    "    words = text.split()  # split into words\n",
    "    return words\n",
    "\n",
    "# Preprocess the documents\n",
    "doc1_words = preprocess(doc1)\n",
    "doc2_words = preprocess(doc2)\n",
    "doc3_words = preprocess(doc3)\n",
    "\n",
    "# Display preprocessed documents\n",
    "print(\"Preprocessed Document 1:\", doc1_words)\n",
    "print(\"Preprocessed Document 2:\", doc2_words)\n",
    "print(\"Preprocessed Document 3:\", doc3_words)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c07086c",
   "metadata": {},
   "source": [
    "## Step 3: Compare Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25e34240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between Document 1 and 2: 0.6666666666666666\n",
      "Similarity between Document 1 and 3: 0.030303030303030304\n",
      "Similarity between Document 2 and 3: 0.029411764705882353\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to compute Jaccard similarity\n",
    "def jaccard_similarity(docx, docy):\n",
    "    set_x = set(docx)\n",
    "    set_y = set(docy)\n",
    "    intersection = set_x.intersection(set_y)\n",
    "    union = set_x.union(set_y)\n",
    "    return len(intersection) / len(union)\n",
    "\n",
    "# Function to compute Euclidean distance\n",
    "def euclidean_distance(docx, docy):\n",
    "    word_set = set(docx) | set(docy)\n",
    "    freqx = {word: docx.count(word) for word in word_set}\n",
    "    freqy = {word: docy.count(word) for word in word_set}\n",
    "    distance = math.sqrt(sum((freqx.get(word, 0) - freqy.get(word, 0))**2 for word in word_set))\n",
    "    return distance\n",
    "\n",
    "# Function to compute Cosine similarity\n",
    "def cosine_similarity(docx, docy):\n",
    "    word_set = set(docx) | set(docy)\n",
    "    freqx = {word: docx.count(word) for word in word_set}\n",
    "    freqy = {word: docy.count(word) for word in word_set}\n",
    "    dot_product = sum(freqx.get(word, 0) * freqy.get(word, 0) for word in word_set)\n",
    "    magnitude_x = math.sqrt(sum(freqx.get(word, 0)**2 for word in word_set))\n",
    "    magnitude_y = math.sqrt(sum(freqy.get(word, 0)**2 for word in word_set))\n",
    "    similarity = dot_product / (magnitude_x * magnitude_y)\n",
    "    return similarity\n",
    "\n",
    "\n",
    "\n",
    "# Calculate similarity\n",
    "similarity_12 = jaccard_similarity(doc1_words, doc2_words)\n",
    "similarity_13 = jaccard_similarity(doc1_words, doc3_words)\n",
    "similarity_23 = jaccard_similarity(doc2_words, doc3_words)\n",
    "\n",
    "# Display the similarities\n",
    "print(\"Similarity between Document 1 and 2:\", similarity_12)\n",
    "print(\"Similarity between Document 1 and 3:\", similarity_13)\n",
    "print(\"Similarity between Document 2 and 3:\", similarity_23)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b54b0346",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'math' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Calculate similarities\u001b[39;00m\n\u001b[0;32m      4\u001b[0m jaccard_similarities \u001b[38;5;241m=\u001b[39m [[jaccard_similarity(preprocessed_docs[i], preprocessed_docs[j]) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m([doc1, doc2, doc3]))] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m([doc1, doc2, doc3]))]\n\u001b[1;32m----> 5\u001b[0m cosine_similarities \u001b[38;5;241m=\u001b[39m [[cosine_similarity(preprocessed_docs[i], preprocessed_docs[j]) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m([doc1, doc2, doc3]))] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m([doc1, doc2, doc3]))]\n\u001b[0;32m      6\u001b[0m euclidean_distances \u001b[38;5;241m=\u001b[39m [[euclidean_distance(preprocessed_docs[i], preprocessed_docs[j]) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m([doc1, doc2, doc3]))] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m([doc1, doc2, doc3]))]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Display the results\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[12], line 5\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Calculate similarities\u001b[39;00m\n\u001b[0;32m      4\u001b[0m jaccard_similarities \u001b[38;5;241m=\u001b[39m [[jaccard_similarity(preprocessed_docs[i], preprocessed_docs[j]) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m([doc1, doc2, doc3]))] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m([doc1, doc2, doc3]))]\n\u001b[1;32m----> 5\u001b[0m cosine_similarities \u001b[38;5;241m=\u001b[39m [[cosine_similarity(preprocessed_docs[i], preprocessed_docs[j]) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m([doc1, doc2, doc3]))] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m([doc1, doc2, doc3]))]\n\u001b[0;32m      6\u001b[0m euclidean_distances \u001b[38;5;241m=\u001b[39m [[euclidean_distance(preprocessed_docs[i], preprocessed_docs[j]) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m([doc1, doc2, doc3]))] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m([doc1, doc2, doc3]))]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Display the results\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[12], line 5\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Calculate similarities\u001b[39;00m\n\u001b[0;32m      4\u001b[0m jaccard_similarities \u001b[38;5;241m=\u001b[39m [[jaccard_similarity(preprocessed_docs[i], preprocessed_docs[j]) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m([doc1, doc2, doc3]))] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m([doc1, doc2, doc3]))]\n\u001b[1;32m----> 5\u001b[0m cosine_similarities \u001b[38;5;241m=\u001b[39m [[\u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocessed_docs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocessed_docs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m([doc1, doc2, doc3]))] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m([doc1, doc2, doc3]))]\n\u001b[0;32m      6\u001b[0m euclidean_distances \u001b[38;5;241m=\u001b[39m [[euclidean_distance(preprocessed_docs[i], preprocessed_docs[j]) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m([doc1, doc2, doc3]))] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m([doc1, doc2, doc3]))]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Display the results\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[9], line 23\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(docx, docy)\u001b[0m\n\u001b[0;32m     21\u001b[0m freqy \u001b[38;5;241m=\u001b[39m {word: docy\u001b[38;5;241m.\u001b[39mcount(word) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m word_set}\n\u001b[0;32m     22\u001b[0m dot_product \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(freqx\u001b[38;5;241m.\u001b[39mget(word, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m*\u001b[39m freqy\u001b[38;5;241m.\u001b[39mget(word, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m word_set)\n\u001b[1;32m---> 23\u001b[0m magnitude_x \u001b[38;5;241m=\u001b[39m \u001b[43mmath\u001b[49m\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;28msum\u001b[39m(freqx\u001b[38;5;241m.\u001b[39mget(word, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m word_set))\n\u001b[0;32m     24\u001b[0m magnitude_y \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;28msum\u001b[39m(freqy\u001b[38;5;241m.\u001b[39mget(word, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m word_set))\n\u001b[0;32m     25\u001b[0m similarity \u001b[38;5;241m=\u001b[39m dot_product \u001b[38;5;241m/\u001b[39m (magnitude_x \u001b[38;5;241m*\u001b[39m magnitude_y)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'math' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "preprocessed_docs = [preprocess(doc) for doc in [doc1, doc2, doc3]]\n",
    "\n",
    "# Calculate similarities\n",
    "jaccard_similarities = [[jaccard_similarity(preprocessed_docs[i], preprocessed_docs[j]) for j in range(len([doc1, doc2, doc3]))] for i in range(len([doc1, doc2, doc3]))]\n",
    "cosine_similarities = [[cosine_similarity(preprocessed_docs[i], preprocessed_docs[j]) for j in range(len([doc1, doc2, doc3]))] for i in range(len([doc1, doc2, doc3]))]\n",
    "euclidean_distances = [[euclidean_distance(preprocessed_docs[i], preprocessed_docs[j]) for j in range(len([doc1, doc2, doc3]))] for i in range(len([doc1, doc2, doc3]))]\n",
    "\n",
    "# Display the results\n",
    "print(\"Jaccard Similarities:\")\n",
    "for row in jaccard_similarities:\n",
    "    print(row)\n",
    "print(\"\\nCosine Similarities:\")\n",
    "for row in cosine_similarities:\n",
    "    print(row)\n",
    "print(\"\\nEuclidean Distances:\")\n",
    "for row in euclidean_distances:\n",
    "    print(row)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
